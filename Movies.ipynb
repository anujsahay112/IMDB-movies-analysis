{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/Anuj_sahay/Documents/Data Science_Python/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40789, 40)\n",
      "   Unnamed: 0              Title  Year      Rated    Released  Runtime  \\\n",
      "0           1  39 Pounds of Love  2005    UNRATED  2005-04-08   70 min   \n",
      "1           2               3:am  2005  NOT RATED  2005-01-25   21 min   \n",
      "2           3    500 Years Later  2005        NaN  2005-02-24  106 min   \n",
      "3           4          5th World  2005        NaN  2005-01-20   75 min   \n",
      "4           5                 90  2005        NaN  2005-03-12   14 min   \n",
      "\n",
      "                             Genre            Director  \\\n",
      "0  Documentary, Biography, Romance         Dani Menkin   \n",
      "1                  Short, Thriller       Ryan Bradford   \n",
      "2                      Documentary  Owen Alik Shahadah   \n",
      "3                   Drama, Romance     Blackhorse Lowe   \n",
      "4                       War, Short          Jason Wise   \n",
      "\n",
      "                         Writer  \\\n",
      "0     Ilan Heitner, Dani Menkin   \n",
      "1  Ryan Bradford, Ryen Schlegel   \n",
      "2                   M.K. Asante   \n",
      "3               Blackhorse Lowe   \n",
      "4                    Jason Wise   \n",
      "\n",
      "                                              Actors ...   \\\n",
      "0                                     Ami Ankilewitz ...    \n",
      "1  Mike Ashworth, Jen Badewitz, Ryan Bradford, Se... ...    \n",
      "2  Kolfi Adu, Sona Jobarteh, Hunter Adams III, Ha... ...    \n",
      "3  Livandrea Knoki, Sheldon Silentwalker, Ernest ... ...    \n",
      "4  Bryan Barnett-Woods, Oto Brezina, Mike Dunn, E... ...    \n",
      "\n",
      "                                           tomatoURL         DVD BoxOffice  \\\n",
      "0  http://www.rottentomatoes.com/m/1175966-color_...  2007-05-29       NaN   \n",
      "1                                                NaN         NaN       NaN   \n",
      "2   http://www.rottentomatoes.com/m/500_years_later/  2008-01-08       NaN   \n",
      "3  http://www.rottentomatoes.com/m/world_poker_5t...  2006-10-31       NaN   \n",
      "4                                                NaN         NaN       NaN   \n",
      "\n",
      "     Production                                            Website  Response  \\\n",
      "0           NaN                                                NaN      True   \n",
      "1           NaN                                                NaN      True   \n",
      "2  Codeblack TV                      http://www.500yearslater.com/      True   \n",
      "3           NaN  http://www.variety.com/review/VE1117926147.htm...      True   \n",
      "4           NaN                                                NaN      True   \n",
      "\n",
      "   Budget  Domestic_Gross Gross Date  \n",
      "0     NaN             NaN   NaN  NaN  \n",
      "1     NaN             NaN   NaN  NaN  \n",
      "2     NaN             NaN   NaN  NaN  \n",
      "3     NaN             NaN   NaN  NaN  \n",
      "4     NaN             NaN   NaN  NaN  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0          Year    Metascore    imdbRating     imdbVotes  \\\n",
      "count   40789.000000  40789.000000  5210.000000  39535.000000  3.949700e+04   \n",
      "mean    25116.814877   1980.954963    54.784261      6.252146  1.205867e+04   \n",
      "std     24214.945395     25.020166    18.049470      1.207422  5.702163e+04   \n",
      "min         1.000000   1888.000000     1.000000      1.000000  5.000000e+00   \n",
      "25%     10414.000000   1962.000000    42.000000      5.600000  6.100000e+01   \n",
      "50%     20691.000000   1989.000000    55.000000      6.400000  2.140000e+02   \n",
      "75%     31696.000000   2001.000000    68.000000      7.100000  1.343000e+03   \n",
      "max    112382.000000   2018.000000   100.000000      9.800000  1.684836e+06   \n",
      "\n",
      "       tomatoMeter  tomatoRating  tomatoReviews  tomatoFresh  tomatoRotten  \\\n",
      "count  9458.000000   9448.000000    9502.000000  9502.000000   9502.000000   \n",
      "mean     58.579192      5.874968      57.375289    34.281309     23.093980   \n",
      "std      28.856973      1.527928      63.167701    46.668462     30.997875   \n",
      "min       0.000000      0.000000       1.000000     0.000000      0.000000   \n",
      "25%      35.000000      4.800000      11.000000     5.000000      3.000000   \n",
      "50%      63.000000      6.000000      28.000000    15.000000      9.000000   \n",
      "75%      83.000000      7.000000      87.000000    43.000000     30.000000   \n",
      "max     100.000000      9.800000     360.000000   343.000000    249.000000   \n",
      "\n",
      "       tomatoUserMeter  tomatoUserRating  tomatoUserReviews        Budget  \\\n",
      "count     18097.000000      18181.000000       2.407100e+04  4.583000e+03   \n",
      "mean         55.542742          3.264760       9.270171e+04  3.178640e+07   \n",
      "std          23.521943          0.558422       1.425632e+06  4.060028e+07   \n",
      "min           0.000000          0.000000       0.000000e+00  1.100000e+03   \n",
      "25%          38.000000          2.900000       4.700000e+01  5.000000e+06   \n",
      "50%          57.000000          3.300000       3.420000e+02  1.800000e+07   \n",
      "75%          75.000000          3.600000       4.935000e+03  4.000000e+07   \n",
      "max         100.000000          5.000000       3.579456e+07  4.250000e+08   \n",
      "\n",
      "       Domestic_Gross         Gross         Date  \n",
      "count    4.583000e+03  4.583000e+03  4583.000000  \n",
      "mean     4.263995e+07  9.029135e+07  2002.823696  \n",
      "std      6.460616e+07  1.669594e+08    12.044254  \n",
      "min      0.000000e+00  0.000000e+00  1915.000000  \n",
      "25%      2.198847e+06  4.670743e+06  1999.000000  \n",
      "50%      1.906824e+07  2.927690e+07  2005.000000  \n",
      "75%      5.472205e+07  1.003587e+08  2011.000000  \n",
      "max      7.605076e+08  2.783919e+09  2017.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie     40000\n",
       "series      725\n",
       "game         64\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies=df[df['Type']==\"movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-76c9590cd5b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Drama'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'movies' is not defined"
     ]
    }
   ],
   "source": [
    "print(sum(movies['Genre'].isnull()))\n",
    "movies['Genre'].fillna('Drama',inplace=True)\n",
    "print(sum(movies['Genre'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_minutes(x):\n",
    "    x=str(x)\n",
    "    m=float('nan')\n",
    "    m=re.match(r\"(\\d+)\\s+h+(\\d+)\\s+m\\w+\",x)\n",
    "    if m is not None:\n",
    "        m=float(m.groups()[0]*60+m.groups()[1])\n",
    "    m=re.match(r\"(\\d+)\\s+m\\w+\",x)\n",
    "    if m is not None:\n",
    "        m=float(m.groups()[0])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Runtime']=list(map(get_minutes,movies['Runtime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(movies['Runtime'].isnull()))\n",
    "movies['Runtime'].fillna(np.mean(movies['Runtime']),inplace=True)\n",
    "print(sum(movies['Runtime'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Runtime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(movies['Runtime']),bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(movies['Budget'].isnull()))\n",
    "movies['Budget'].fillna(np.mean(movies['Budget']),inplace=True)\n",
    "print(sum(movies['Budget'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(movies['Budget']),bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(movies['Year'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(movies['Year']),bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wins and Nominations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def nominations(a):\n",
    "    a=str(a).lower()\n",
    "    nom_1=0\n",
    "    nom_2=0\n",
    "    nom=0\n",
    "    n1=re.findall(r\"nominated\\sfor\\s\\d+\",a,re.I|re.M)\n",
    "    n2=re.findall(r\"\\d+\\s+nomination\\w+\",a,re.I|re.M)\n",
    "    \n",
    "    if(len(n1)>0):\n",
    "        nom_1=int(re.match(r\"\\w+\\s+\\w+\\s+(\\d+)\",n1[0]).groups()[0])\n",
    "    if(len(n2)>0):\n",
    "        nom_2=int(re.match(r\"(\\d+)\\s+\\w+\",n2[0]).groups()[0])\n",
    "    nom=nom_1+nom_2\n",
    "    return nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Nominations']=list(map(nominations,movies['Awards']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def wins(a):\n",
    "    a=str(a).lower()\n",
    "    win1=0\n",
    "    win2=0\n",
    "    win=0\n",
    "    w1=re.findall(r\"won\\s\\d+\",a,re.I|re.M)\n",
    "    w2=re.findall(r\"\\d+\\s+wins\\w+\",a,re.I|re.M)\n",
    "    \n",
    "    if(len(w1)>0):\n",
    "        win1=int(re.match(r\"\\w+\\s+(\\d+)\",w1[0]).groups()[0])\n",
    "    if(len(w2)>0):\n",
    "        win2=int(re.match(r\"(\\d+)\\s+\\w+\",w2[0]).groups()[0])\n",
    "    win=win1+win2\n",
    "    return win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Wins']=list(map(wins,movies['Awards']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all=[]\n",
    "all_genres=[]\n",
    "unique_all=[]\n",
    "for i in movies['Genre']:\n",
    "        new_all.append(str(i).split(','))\n",
    "new_all=list(chain(*new_all))\n",
    "for i in new_all:\n",
    "    all_genres.append(i.strip())\n",
    "unique_all=set(all_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "for i in unique_all:\n",
    "    d[i]=[]\n",
    "    for j in movies['Genre']:\n",
    "        j=str(j).strip()\n",
    "        if i in j:\n",
    "            d[i].append(1)\n",
    "        else:\n",
    "            d[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(d['War'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in d.keys():\n",
    "    #for i in range(len(movies['Genre'])):\n",
    "    list_key=pd.Series(d[keys])\n",
    "        #movies[keys].loc[i]=d[keys][i]\n",
    "    movies[keys]=d[keys]    \n",
    "    #movies.insert(loc=0,column=keys,value=d[keys])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(movies['War'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all=[]\n",
    "all_genres=[]\n",
    "unique_all=[]\n",
    "for i in movies['Genre']:\n",
    "        new_all.append(str(i).split(','))\n",
    "new_all=list(chain(*new_all))\n",
    "for i in new_all:\n",
    "    all_genres.append(i.strip())\n",
    "unique_all=set(all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count={}\n",
    "for i in unique_all:\n",
    "    count[i]=1\n",
    "    for j in new_all:\n",
    "        if i in j:\n",
    "            count[i]=count[i]+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_count=sorted(count.items(),key=lambda x:x[1],reverse=True)\n",
    "print(sorted_count)\n",
    "top10=sorted_count[0:10]\n",
    "print(top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "name=[]\n",
    "for i in range(len(top10)):\n",
    "    x.append(top10[i][1])\n",
    "    name.append(top10[i][0])\n",
    "print(x)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.arange(len(name))\n",
    " \n",
    "plt.barh(y_pos, x, align='center', alpha=1)\n",
    "plt.yticks(y_pos, name)\n",
    "plt.ylabel('Frequency Of Genres')\n",
    "plt.title('Top 10 Genres')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrrelation and Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies['Runtime'].corr(movies['Year']))\n",
    "plt.scatter(movies['Runtime'],movies['Year'])\n",
    "plt.xlabel(\"Runtime\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.title(\"Corr between Runtime and Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies['Gross'].corr(movies['Budget']))\n",
    "plt.scatter(movies['Gross'],movies['Budget'])\n",
    "plt.xlabel(\"Gross\")\n",
    "plt.ylabel(\"Budget\")\n",
    "plt.title(\"Corr between Gross and Budget\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies['Gross'].corr(movies['Wins']))\n",
    "plt.scatter(movies['Gross'],movies['Wins'])\n",
    "plt.xlabel(\"Gross\")\n",
    "plt.ylabel(\"Wins\")\n",
    "plt.title(\"Corr between Gross and Wins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies['Gross'].corr(movies['Nominations']))\n",
    "plt.scatter(movies['Gross'],movies['Nominations'])\n",
    "plt.xlabel(\"Gross\")\n",
    "plt.ylabel(\"Nominations\")\n",
    "plt.title(\"Corr between Gross and Nominations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies['tomatoRating'].corr(movies['imdbRating']))\n",
    "plt.scatter(movies['tomatoRating'],movies['imdbRating'])\n",
    "plt.xlabel(\"tomato Rating\")\n",
    "plt.ylabel(\"Imdb Rating\")\n",
    "plt.title(\"Corr between Tomato Rating and Imdb Rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies['Budget'].corr(movies['Year']))\n",
    "plt.scatter(movies['Budget'],movies['Year'])\n",
    "plt.xlabel(\"Budget\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.title(\"Corr between Budget and Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gross Value Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(movies['Gross'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(subset=['Gross'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(movies['Gross'].isnull()))\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Greater than Year 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=movies[movies['Year']>2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting only Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new=movies.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "print(movies_new.shape)\n",
    "movies_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['Metascore'].describe()\n",
    "print(sum(movies_new['Metascore'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['Metascore'].fillna(np.mean(movies_new['Metascore']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['imdbRating'].describe()\n",
    "movies_new['imdbRating'].value_counts()\n",
    "sum(movies_new['imdbRating'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['imdbRating'].fillna(np.mean(movies_new['imdbRating']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['imdbVotes'].describe()\n",
    "movies_new['imdbVotes'].value_counts()\n",
    "sum(movies_new['imdbVotes'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['imdbVotes'].fillna(np.mean(movies_new['imdbVotes']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['tomatoMeter'].describe()\n",
    "movies_new['tomatoMeter'].value_counts()\n",
    "sum(movies_new['tomatoMeter'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['tomatoMeter'].fillna(np.mean(movies_new['tomatoMeter']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['tomatoFresh'].fillna(np.mean(movies_new['tomatoFresh']),inplace=True)\n",
    "movies_new['tomatoRating'].fillna(np.mean(movies_new['tomatoRating']),inplace=True)\n",
    "movies_new['tomatoRotten'].fillna(np.mean(movies_new['tomatoRotten']),inplace=True)\n",
    "movies_new['tomatoUserMeter'].fillna(np.mean(movies_new['tomatoUserMeter']),inplace=True)\n",
    "movies_new['tomatoUserRating'].fillna(np.mean(movies_new['tomatoUserRating']),inplace=True)\n",
    "movies_new['tomatoUserReviews'].fillna(np.mean(movies_new['tomatoUserReviews']),inplace=True)\n",
    "movies_new['tomatoReviews'].fillna(np.mean(movies_new['tomatoReviews']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=movies_new.loc[:,movies_new.columns !='Gross']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.loc[:,X.columns !='Unnamed: 0']\n",
    "#X=X.reset_index()\n",
    "#X=X.loc[:,X.columns !='index']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=movies_new['Gross']\n",
    "Y.head()\n",
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_linear=LinearRegression(normalize=True)\n",
    "model_linear.fit(X_train, Y_train)\n",
    "print(\"Linear Model:\", model_linear)\n",
    "print(\"coeffecients:\", model_linear.coef_)\n",
    "print(\"Intercept:\", model_linear.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R squared value:', model_linear.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=list(range(1,2400,200))\n",
    "print(train_set)\n",
    "print(type(train_set))\n",
    "train_set.append(2530)\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "                                                   estimator = LinearRegression(), X = X,\n",
    "                                                   y = Y, train_sizes = train_set, cv = 5,\n",
    "                                                   scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 40) # separator\n",
    "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "plt.plot(train_set, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_set, validation_scores_mean, label = 'Validation error')\n",
    "\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "#plt.ylim(0,40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes,-validation_scores)\n",
    "plt.ylabel('validation Scores')\n",
    "plt.xlabel('Train/Test Size')\n",
    "plt.title(\"Validation Scores Vs Test/Train Split Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predictions = model_linear.predict(X_test)\n",
    "#Y_predictions[Y_predictions<0]=0\n",
    "print(Y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_test, Y_predictions,'ro')\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoxCox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list(X.columns):\n",
    "    plt.hist(X[x], bins=20)\n",
    "    plt.title(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "XT = X.copy()\n",
    "\n",
    "l=['Year','Runtime','Year', 'Runtime', 'Metascore', 'imdbRating', 'imdbVotes', 'tomatoRating', 'tomatoReviews', 'Budget', 'Date']\n",
    "\n",
    "print(l)\n",
    "for i in l:\n",
    "    XT[i] = stats.boxcox(X[i])[0]\n",
    "    print(i,np.min(XT[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT['tomatoMeter'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "XT_train, XT_test, Y_train, Y_test = train_test_split(XT, Y, test_size=0.2, random_state=42)\n",
    "print(XT_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_linear=LinearRegression(normalize=True)\n",
    "model_linear.fit(XT_train, Y_train)\n",
    "print(\"Linear Model:\", model_linear)\n",
    "print(\"coeffecients:\", model_linear.coef_)\n",
    "print(\"Intercept:\", model_linear.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R squared value:', model_linear.score(XT_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=list(range(1,2400,200))\n",
    "print(train_set)\n",
    "print(type(train_set))\n",
    "train_set.append(2530)\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "                                                   estimator = LinearRegression(), X = XT,\n",
    "                                                   y = Y, train_sizes = train_set, cv = 5,\n",
    "                                                   scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 40) # separator\n",
    "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "plt.plot(train_set, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_set, validation_scores_mean, label = 'Validation error')\n",
    "\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "#plt.ylim(0,40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes,-validation_scores)\n",
    "plt.ylabel('validation Scores')\n",
    "plt.xlabel('Train/Test Size')\n",
    "plt.title(\"Validation Scores Vs Test/Train Split Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical to Discrete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new=movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvalues(a):\n",
    "    new_all=[]\n",
    "    all_genres=[]\n",
    "    unique_all=[]\n",
    "    for i in a:\n",
    "        new_all.append(str(i).split(','))\n",
    "    new_all=list(chain(*new_all))\n",
    "    for i in new_all:\n",
    "        all_genres.append(i.strip())\n",
    "    unique_all=set(all_genres)\n",
    "    d={}\n",
    "    for i in unique_all:\n",
    "        d[i]=[]\n",
    "        for j in a:\n",
    "            j=str(j).strip()\n",
    "            if i in j:\n",
    "                d[i].append(1)\n",
    "            else:\n",
    "                d[i].append(0)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country=getvalues(movies['Country'])\n",
    "print(sum(country['USA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addindataframe(d):\n",
    "    for keys in d.keys():\n",
    "    #for i in range(len(movies['Genre'])):\n",
    "        list_key=pd.Series(d[keys])\n",
    "        #movies[keys].loc[i]=d[keys][i]\n",
    "        movies_new[keys]=d[keys]    \n",
    "    #movies.insert(loc=0,column=keys,value=d[keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addindataframe(getvalues(movies_new['Country']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addindataframe(getvalues(movies_new['Language']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addindataframe(getvalues(movies_new['Rated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.head())\n",
    "sum(movies_new['USA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting only Numerical Data (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies_new.shape)\n",
    "movies_new=movies_new.select_dtypes(include='number')\n",
    "print(movies_new.shape)\n",
    "movies_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['Metascore'].fillna(np.mean(movies_new['Metascore']),inplace=True)\n",
    "movies_new['imdbRating'].fillna(np.mean(movies_new['imdbRating']),inplace=True)\n",
    "movies_new['imdbVotes'].fillna(np.mean(movies_new['imdbVotes']),inplace=True)\n",
    "movies_new['tomatoMeter'].fillna(np.mean(movies_new['tomatoMeter']),inplace=True)\n",
    "movies_new['tomatoFresh'].fillna(np.mean(movies_new['tomatoFresh']),inplace=True)\n",
    "movies_new['tomatoRating'].fillna(np.mean(movies_new['tomatoRating']),inplace=True)\n",
    "movies_new['tomatoRotten'].fillna(np.mean(movies_new['tomatoRotten']),inplace=True)\n",
    "movies_new['tomatoUserMeter'].fillna(np.mean(movies_new['tomatoUserMeter']),inplace=True)\n",
    "movies_new['tomatoUserRating'].fillna(np.mean(movies_new['tomatoUserRating']),inplace=True)\n",
    "movies_new['tomatoUserReviews'].fillna(np.mean(movies_new['tomatoUserReviews']),inplace=True)\n",
    "movies_new['tomatoReviews'].fillna(np.mean(movies_new['tomatoReviews']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(movies_new.columns):\n",
    "    print(i,sum(movies_new[i].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=movies_new.loc[:,movies_new.columns !='Gross']\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=X_new.loc[:,X_new.columns !='Unnamed: 0']\n",
    "#X=X.reset_index()\n",
    "#X=X.loc[:,X.columns !='index']\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new=movies_new['Gross']\n",
    "Y_new.head()\n",
    "Y_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train_new, X_test_new, Y_train_new, Y_test_new = train_test_split(X_new, Y_new, test_size=0.2, random_state=45)\n",
    "print(X_train_new.head())\n",
    "print(Y_train_new.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_linear_new=LinearRegression(normalize=True)\n",
    "model_linear_new.fit(X_train_new, Y_train_new)\n",
    "print(\"Linear Model:\", model_linear)\n",
    "print(\"coeffecients:\", model_linear.coef_)\n",
    "print(\"Intercept:\", model_linear.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predictions_new = model_linear_new.predict(X_test_new)\n",
    "print(Y_predictions_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R squared value:', model_linear_new.score(X_test_new, Y_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new=list(range(1,2400,200))\n",
    "print(train_set_new)\n",
    "print(type(train_set_new))\n",
    "train_set_new.append(2530)\n",
    "print(train_set_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "                                                   estimator = LinearRegression(), X = X_new,\n",
    "                                                   y = Y_new, train_sizes = train_set_new, cv = 5,\n",
    "                                                   scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 40) # separator\n",
    "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "plt.plot(train_set_new, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_set_new, validation_scores_mean, label = 'Validation error')\n",
    "\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "#plt.ylim(0,40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes,-validation_scores)\n",
    "plt.ylabel('validation Scores')\n",
    "plt.xlabel('Train/Test Size')\n",
    "plt.title(\"Validation Scores Vs Test/Train Split Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
